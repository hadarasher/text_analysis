{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:</h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Text Analysis</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)</b> (moodle example)<br/>\n",
    "&#x2714; <b>(brief review) All previous notebooks</b><br/>\n",
    "</div> \n",
    "<h5><u>Review the presentations regarding the following topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis</b> (lecture presentation)<br/>\n",
    "&#x2714; <b>(brief review) All other presentations</b><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details Student 1: Hadar Asher, 207767005, hadarasher99@gmail.com\n",
    "# Details Student 2: Or Milles, 322721663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis and String manipulation imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net installation:\n",
    "\n",
    "# unmark if you want to use and need to install\n",
    "!pip install wn\n",
    "!python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "import wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer installation:\n",
    "\n",
    "# unmark if you want to use and need to install:\n",
    "!pip install hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing data.</br>\n",
    "We can see that there are few duplicates. We'll found and drop them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Engeneering -</b></br>\n",
    "Transfer 'gender'column from string values to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['gender']=df_train['gender'].replace({'m':0,'f':1})\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of male and female statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting with cleaning the text, keeping Hebrew characters only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_hebrew(text):\n",
    "    return re.sub(r'[^א-ת\\s]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_hebrew(text):\n",
    "    tokens = ht.tokenize(text)\n",
    "    token_list = []\n",
    "    for token in tokens:\n",
    "        token_list.append(token[1])\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting with tokenization using hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline_mnb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize_hebrew)),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid_mnb = {\n",
    "    'tfidf__max_features': [1000, 5000, 10000],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__smooth_idf': [True, False],\n",
    "    'clf__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "    'clf__fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_mnb = GridSearchCV(pipeline_mnb, param_grid_mnb, cv=10, scoring='f1_macro')\n",
    "grid_search_mnb.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "print(\"Best Parameters (MultinomialNB):\", grid_search_mnb.best_params_)\n",
    "print(\"Best F1 Macro Score (MultinomialNB):\", grid_search_mnb.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "pipeline_perceptron = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize_hebrew)),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', Perceptron())\n",
    "])\n",
    "\n",
    "param_grid_perceptron = {\n",
    "    'tfidf__max_features': [1000, 5000, 10000],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__smooth_idf': [True, False],\n",
    "    'clf__alpha': [0.0001, 0.001, 0.01],\n",
    "    'clf__penalty': [None, 'l1', 'l2', 'elasticnet'],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "    'clf__max_iter': [100, 1000]\n",
    "}\n",
    "\n",
    "grid_search_perceptron = GridSearchCV(pipeline_perceptron, param_grid_perceptron, cv=10, scoring='f1_macro')\n",
    "grid_search_perceptron.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "print(\"Best Parameters (Perceptron):\", grid_search_perceptron.best_params_)\n",
    "print(\"Best F1 Macro Score (Perceptron):\", grid_search_perceptron.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipeline_sgd = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize_hebrew)),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "param_grid_sgd = {\n",
    "    'tfidf__max_features': [1000, 5000, 10000],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__smooth_idf': [True, False],\n",
    "    'clf__alpha': [0.0001, 0.001, 0.01],\n",
    "    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'clf__loss': ['hinge', 'log', 'modified_huber'],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "    'clf__max_iter': [100, 1000]\n",
    "}\n",
    "\n",
    "grid_search_sgd = GridSearchCV(pipeline_sgd, param_grid_sgd, cv=10, scoring='f1_macro')\n",
    "grid_search_sgd.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "print(\"Best Parameters (SGDClassifier):\", grid_search_sgd.best_params_)\n",
    "print(\"Best F1 Macro Score (SGDClassifier):\", grid_search_sgd.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize_hebrew)),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid_knn = {\n",
    "    'tfidf__max_features': [1000, 5000, 10000],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__smooth_idf': [True, False],\n",
    "    'clf__n_neighbors': [3, 5, 7],\n",
    "    'clf__weights': ['uniform', 'distance'],\n",
    "    'clf__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'clf__p': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(pipeline_knn, param_grid_knn, cv=10, scoring='f1_macro')\n",
    "grid_search_knn.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "print(\"Best Parameters (KNeighborsClassifier):\", grid_search_knn.best_params_)\n",
    "print(\"Best F1 Macro Score (KNeighborsClassifier):\", grid_search_knn.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize_hebrew)),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "param_grid_dt = {\n",
    "    'tfidf__max_features': [1000, 5000, 10000],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__smooth_idf': [True, False],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [None, 10, 20],\n",
    "    'clf__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(pipeline_dt, param_grid_dt, cv=10, scoring='f1_macro')\n",
    "grid_search_dt.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "print(\"Best Parameters (DecisionTreeClassifier):\", grid_search_dt.best_params_)\n",
    "print(\"Best F1 Macro Score (DecisionTree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipeline_svc = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize_hebrew)),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "param_grid_svc = {\n",
    "    'tfidf__max_features': [1000, 5000, 10000],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__smooth_idf': [True, False],\n",
    "    'clf__C': [0.1, 1.0, 10.0],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "    'clf__max_iter': [100, 1000]\n",
    "}\n",
    "\n",
    "grid_search_svc = GridSearchCV(pipeline_svc, param_grid_svc, cv=10, scoring='f1_macro')\n",
    "grid_search_svc.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "print(\"Best Parameters (LinearSVC):\", grid_search_svc.best_params_)\n",
    "print(\"Best F1 Macro Score (LinearSVC):\", grid_search_svc.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the train set to X set and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv (optional)\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
